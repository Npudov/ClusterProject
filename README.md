# ClusterProject
Big data project, deploy three clusters in docker

В рамках данного проекта была использована предметная область ресторан.
Предметная область была разбита на три NoSQL базы, каждая из которых является кластером как минимум из трёх узлов
Были выбраны следующие NoSQL базы - Mongo, Cassandra, Neo4j

В Mongo хранилось меню ресторана, данные были следующими:

•	_id – идентификатор (ключ)

•	dish_name – наименование блюда

•	price - цена

•	category – категория (первое блюдо, второе блюдо, напитки, десерт)

В Cassandra хранились данные о клиентах ресторана (программа лояльности) и данные о работниках ресторана. Пространство ключей у них одно – restaurants. Получилось две таблицы:
Table Clients:

•	client_id – идентификатор клиента

•	client_lastname - фамилия клиента

•	client_firstname – имя клиента

•	phone - телефон

•	balance – сумма на бонусном счёте

•	status – статус в программе лояльности (бронзовый, серебряный, золотой)

PRIMARY KEY ((client_id), client_lastname, client_firstname)

Table Employers:

•	employer_id – идентификатор работника

•	employer_lastname – фамилия работника

•	employer_firstname – имя работника

•	position – позиция

•	salary – зарплата

PRIMARY KEY ((employer_id), employer_lastname, employer_firstname)

В Neo4j хранилась информация о связях между клиентами, официантами и столами. Официанты обслуживали столы, клиенты резервировали столы.
В базе содержалось три узла: Clients, Officiants, Tables
У Clients свойства: id-ключ, client_name – фамилия + имя.

У Officiants свойства: id-ключ, officiant_name- фамилия + имя.

У Tables свойства:id-ключ, table_number – номер стола

Связь между Clients и Tables – reserved (зарезирвировано)

Связь между Officiants и Tables – serve (обслуживается)

Все базы поднимались как кластер при помощи docker-compose. Для каждой из баз был написан свой docker-compose и осуществлено развёртывание в Docker.
Обращу внимание, что для Neo4j предварительно необходимо в папке с базой создать файл конфигурации neo4j.conf. Также для Neo4J заранее был написан скрипт для генерации данных в формате csv. Он приложен в исходниках

Поскольку у нас кластеры, то следовательно у нас происходит репликация данных и имеется лидер. В случае отключения лидера в кластере будут проходить выборы нового лидера

Для запуска кластеров при помощи docker-compose перейдите в папку, где у вас будет храниться база и её данные и выполните последовательность следующих команд:

```docker-compose build```

```docker-compose up```

После выполнения данных команд ваши кластера будут запущены в docker. Поскольку у нас три базы и следовательно три кластера, то и делать такую последовательность действий нужно для каждой из трёх наших баз. Особенности написания docker-compose для конкретной базы можно посмотреть в исходниках с комментариями.

В рамках проекта были написаны блокноты в jupyter notebook на Python, осуществлена генерация осмысленных рандомных данных для каждой из баз в размере 2 млн записей, разработаны методы для получения определенных данных из базы (запросы по API).

Также были осуществлены замеры времени вставки для каждой из баз и время выполнения различных запросов в каждой из баз. Примеры взаимодействия и выходные данные приведены в соотвествующих блокнотах

К проекту прилагается сопроводительное описание и основные выжимки из исходного кода

Файл сгенерированных данных для neo4j в силу большого размера прилагаю на Google drive: https://drive.google.com/file/d/12MDUxNfYzjZSTV-DV0OArSOBfkEY2BXh/view?usp=sharing
